<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Research | MIC Lab @ KOREATECH</title><meta name=keywords content><meta name=description content="
Our lab focuses on developing intelligent perception, efficient AI systems, and physically grounded AI that interact with the real world.

Computer Vision
We study fundamental and applied problems in visual perception.

Object detection, tracking, and segmentation
Feature extraction and matching
Representation learning for visual understanding
Vision-based motion and scene analysis

Related R&amp;D Projects

&ldquo;The development of 50m range ToF CMOS sensor, optical system and signal processing for automotive&rdquo; (KEIT, &lsquo;17.04 ~ &lsquo;21.03)

Demo: Depth-image based object detection (not RGB-image based)




  
    
    
  
  
    Demo Video — Open in YouTube
  


&ldquo;The development of 4D reconstruction and dynamic deformable action model based hyper realistic service technology&rdquo; (GigaKorea, &lsquo;17.04 ~ &lsquo;20.12)

Demo: Progressive 3D human reconstruction based on single RGB camera




  
    
    
  
  
    Demo Video — Open in YouTube
  


On-Device AI
We develop efficient AI models that can run on resource-constrained devices."><meta name=author content><link rel=canonical href=https://miclab-koreatech.github.io/research/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://miclab-koreatech.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://miclab-koreatech.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://miclab-koreatech.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://miclab-koreatech.github.io/apple-touch-icon.png><link rel=mask-icon href=https://miclab-koreatech.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://miclab-koreatech.github.io/research/index.xml title=rss><link rel=alternate hreflang=en href=https://miclab-koreatech.github.io/research/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://miclab-koreatech.github.io/research/"><meta property="og:site_name" content="MIC Lab @ KOREATECH"><meta property="og:title" content="Research"><meta property="og:description" content="
Our lab focuses on developing intelligent perception, efficient AI systems, and physically grounded AI that interact with the real world.
Computer Vision We study fundamental and applied problems in visual perception.
Object detection, tracking, and segmentation Feature extraction and matching Representation learning for visual understanding Vision-based motion and scene analysis Related R&amp;D Projects “The development of 50m range ToF CMOS sensor, optical system and signal processing for automotive” (KEIT, ‘17.04 ~ ‘21.03) Demo: Depth-image based object detection (not RGB-image based) Demo Video — Open in YouTube “The development of 4D reconstruction and dynamic deformable action model based hyper realistic service technology” (GigaKorea, ‘17.04 ~ ‘20.12) Demo: Progressive 3D human reconstruction based on single RGB camera Demo Video — Open in YouTube On-Device AI We develop efficient AI models that can run on resource-constrained devices."><meta property="og:locale" content="ko-kr"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Research"><meta name=twitter:description content="Computer Vision · On-Device AI · Digital Human & Sports AI · Physical AI"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Research","item":"https://miclab-koreatech.github.io/research/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://miclab-koreatech.github.io/ accesskey=h title="MIC Lab (Alt + H)"><img src=https://miclab-koreatech.github.io/images/favicon_transparent.png alt aria-label=logo height=40>MIC Lab</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://miclab-koreatech.github.io/news/ title=News><span>News</span></a></li><li><a href=https://miclab-koreatech.github.io/members/ title=Members><span>Members</span></a></li><li><a href=https://miclab-koreatech.github.io/research/ title=Research><span class=active>Research</span></a></li><li><a href=https://miclab-koreatech.github.io/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://miclab-koreatech.github.io/album/ title=Album><span>Album</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Research</h1></header><div class=post-content><p><img alt="Reserach Overview" loading=lazy src=/images/research/research.png></p><p>Our lab focuses on developing <strong>intelligent perception, efficient AI systems, and physically grounded AI</strong> that interact with the real world.</p><hr><h2 id=computer-vision>Computer Vision<a hidden class=anchor aria-hidden=true href=#computer-vision>#</a></h2><p>We study fundamental and applied problems in visual perception.</p><ul><li>Object detection, tracking, and segmentation</li><li>Feature extraction and matching</li><li>Representation learning for visual understanding</li><li>Vision-based motion and scene analysis</li></ul><h3 id=related-rd-projects>Related R&amp;D Projects<a hidden class=anchor aria-hidden=true href=#related-rd-projects>#</a></h3><ul><li>&ldquo;The development of 50m range ToF CMOS sensor, optical system and signal processing for automotive&rdquo; (KEIT, &lsquo;17.04 ~ &lsquo;21.03)<ul><li>Demo: Depth-image based object detection (not RGB-image based)</li></ul></li></ul><div style="border:1px solid rgba(0,0,0,8%);border-radius:16px;padding:14px;margin:18px 0"><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;border-radius:12px><iframe src=https://www.youtube.com/embed/JDPBF_mnr1Q title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%></iframe></div><div style=margin-top:10px;font-size:14px;opacity:.75>Demo Video — <a href="https://www.youtube.com/watch?v=JDPBF_mnr1Q" target=_blank rel=noopener>Open in YouTube</a></div></div><ul><li>&ldquo;The development of 4D reconstruction and dynamic deformable action model based hyper realistic service technology&rdquo; (GigaKorea, &lsquo;17.04 ~ &lsquo;20.12)<ul><li>Demo: Progressive 3D human reconstruction based on single RGB camera</li></ul></li></ul><div style="border:1px solid rgba(0,0,0,8%);border-radius:16px;padding:14px;margin:18px 0"><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;border-radius:12px><iframe src=https://www.youtube.com/embed/BlU_26OWNiI title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%></iframe></div><div style=margin-top:10px;font-size:14px;opacity:.75>Demo Video — <a href="https://www.youtube.com/watch?v=BlU_26OWNiI" target=_blank rel=noopener>Open in YouTube</a></div></div><hr><h2 id=on-device-ai>On-Device AI<a hidden class=anchor aria-hidden=true href=#on-device-ai>#</a></h2><p>We develop efficient AI models that can run on resource-constrained devices.</p><ul><li>Lightweight and efficient neural network design</li><li>Model compression, quantization, and pruning</li><li>Real-time inference on mobile and edge devices</li><li>Deployment-aware training and optimization</li></ul><h3 id=related-rd-projects-1>Related R&amp;D Projects<a hidden class=anchor aria-hidden=true href=#related-rd-projects-1>#</a></h3><ul><li>&ldquo;Development of intelligent media aspect ratio conversion technology that maintains properties&rdquo; (IITP, &lsquo;21.04 ~ &lsquo;24.12)<ul><li>Demo: Real-time image super-resolution on mobile devices</li></ul></li></ul><div style="border:1px solid rgba(0,0,0,8%);border-radius:16px;padding:14px;margin:18px 0"><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;border-radius:12px><iframe src=https://www.youtube.com/embed/_n_hn5w8A5I title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%></iframe></div><div style=margin-top:10px;font-size:14px;opacity:.75>Demo Video — <a href="https://www.youtube.com/watch?v=_n_hn5w8A5I" target=_blank rel=noopener>Open in YouTube</a></div></div>- Demo: Real-time Media Aspect Ratio Conversion on mobile devices<div style="border:1px solid rgba(0,0,0,8%);border-radius:16px;padding:14px;margin:18px 0"><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;border-radius:12px><iframe src=https://www.youtube.com/embed/Xrb7733a0qk title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%></iframe></div><div style=margin-top:10px;font-size:14px;opacity:.75>Demo Video — <a href="https://www.youtube.com/watch?v=Xrb7733a0qk" target=_blank rel=noopener>Open in YouTube</a></div></div><hr><h2 id=digital-human--sports-ai>Digital Human & Sports AI<a hidden class=anchor aria-hidden=true href=#digital-human--sports-ai>#</a></h2><p>We aim to model, analyze, and simulate human motion and behavior.</p><ul><li>Human pose estimation and motion analysis</li><li>Digital human modeling and simulation</li><li>Personalized exercise and sports training AI</li><li>AI-based performance analysis and feedback</li></ul><h3 id=related-rd-projects-2>Related R&amp;D Projects<a hidden class=anchor aria-hidden=true href=#related-rd-projects-2>#</a></h3><ul><li>&ldquo;Development of metaverse-based sports play tweening and realistic technology&rdquo; (KOCCA, &lsquo;22.04 ~ &lsquo;24.12)<ul><li>Demo: Real-time 3d skeleton extraction for golf swing</li></ul></li></ul><div style="border:1px solid rgba(0,0,0,8%);border-radius:16px;padding:14px;margin:18px 0"><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;border-radius:12px><iframe src=https://www.youtube.com/embed/kHtLy98eb9E title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%></iframe></div><div style=margin-top:10px;font-size:14px;opacity:.75>Demo Video — <a href="https://www.youtube.com/watch?v=kHtLy98eb9E" target=_blank rel=noopener>Open in YouTube</a></div></div><hr><h2 id=physical-ai>Physical AI<a hidden class=anchor aria-hidden=true href=#physical-ai>#</a></h2><p>We study <strong>AI systems that perceive, reason, and act in the physical world</strong> by tightly integrating perception, decision-making, and control.</p><ul><li>Vision-based robotic perception and state estimation</li><li>Learning-based control and decision-making</li><li>Embodied AI and sensorimotor learning</li><li>Human–robot interaction and physical intelligence</li><li>Integration of Computer Vision and On-Device AI for real-world robotics</li></ul><h3 id=related-rd-projects-3>Related R&amp;D Projects<a hidden class=anchor aria-hidden=true href=#related-rd-projects-3>#</a></h3><ul><li>&ldquo;Preparing&rdquo;</li></ul></div></main><footer class=footer><span>&copy; 2026 <a href=https://miclab-koreatech.github.io/>MIC Lab @ KOREATECH</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>